import { useEffect, useRef, useState, useCallback } from 'react';
import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';

export interface PointerPosition {
  x: number;
  y: number;
  confidence: number;
  isTracking: boolean;
}

export interface GestureState {
  direction: 'none' | 'up' | 'down';
  distance: number;
  duration: number;
}

const NOSE_LANDMARK_INDEX = 1; // MediaPipeã®é¼»ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

export function useNosePointer() {
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const faceLandmarkerRef = useRef<FaceLandmarker | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  const [pointerPosition, setPointerPosition] = useState<PointerPosition>({
    x: 0,
    y: 0,
    confidence: 0,
    isTracking: false,
  });

  const [gestureState, setGestureState] = useState<GestureState>({
    direction: 'none',
    distance: 0,
    duration: 0,
  });

  const [isInitialized, setIsInitialized] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [debugInfo, setDebugInfo] = useState<Record<string, string>>({});
  const [sensitivity, setSensitivity] = useState(2.0);

  // å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®é¼»ä½ç½®ã‚’è¿½è·¡ï¼ˆã‚¸ã‚§ã‚¹ãƒãƒ£æ¤œå‡ºç”¨ï¼‰
  const prevNosePosRef = useRef<{ x: number; y: number } | null>(null);
  const gestureStartTimeRef = useRef<number | null>(null);
  const gestureStartPosRef = useRef<{ x: number; y: number } | null>(null);

  // MediaPipeã®åˆæœŸåŒ–
  const initializeFaceLandmarker = useCallback(async () => {
    try {
      console.log('ğŸ”§ Initializing MediaPipe FaceLandmarker...');
      setDebugInfo((prev) => ({ ...prev, status: 'Initializing MediaPipe...' }));

      // å…¬å¼CDNãƒ‘ã‚¹ã‚’ä½¿ç”¨
      const wasmPath = 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm';

      console.log(`ğŸ“¦ Loading WASM from: ${wasmPath}`);
      setDebugInfo((prev) => ({ ...prev, wasmPath }));

      const filesetResolver = await FilesetResolver.forVisionTasks(wasmPath);
      console.log('âœ… FilesetResolver created');
      setDebugInfo((prev) => ({ ...prev, filesetResolver: 'Created' }));

      console.log('ğŸ¤– Creating FaceLandmarker...');
      const landmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath:
            'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
        },
        runningMode: 'VIDEO',
        numFaces: 1,
      });

      faceLandmarkerRef.current = landmarker;
      console.log('âœ… MediaPipe FaceLandmarker initialized successfully');
      setDebugInfo((prev) => ({ ...prev, status: 'MediaPipe Ready' }));
      setIsInitialized(true);
      setError(null);
    } catch (err) {
      const message = err instanceof Error ? err.message : 'Failed to initialize MediaPipe';
      console.error('âŒ MediaPipe initialization error:', err);
      setDebugInfo((prev) => ({ ...prev, error: message }));
      setError(`MediaPipeã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${message}`);
    }
  }, []);

  // ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã®é–‹å§‹
  const startVideoStream = useCallback(async () => {
    try {
      console.log('ğŸ“¹ Requesting camera access...');
      setDebugInfo((prev) => ({ ...prev, camera: 'Requesting...' }));

      // ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³å¯¾å¿œï¼šè¤‡æ•°ã®ã‚«ãƒ¡ãƒ©è¨­å®šã‚’è©¦ã™
      const constraints = [
        // ç¬¬1å„ªå…ˆï¼šãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ï¼ˆã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ï¼‰
        { video: { facingMode: { ideal: 'user' }, width: { ideal: 1280 }, height: { ideal: 720 } } },
        // ç¬¬2å„ªå…ˆï¼šãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ï¼ˆå¿…é ˆï¼‰
        { video: { facingMode: 'user' } },
        // ç¬¬3å„ªå…ˆï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ¡ãƒ©
        { video: true },
      ];

      let stream: MediaStream | null = null;
      let lastError: Error | null = null;

      for (const constraint of constraints) {
        try {
          console.log('ğŸ¥ Trying constraint:', constraint);
          stream = await navigator.mediaDevices.getUserMedia(constraint);
          console.log('âœ… Camera access granted with constraint:', constraint);
          setDebugInfo((prev) => ({ ...prev, camera: 'Connected' }));
          break;
        } catch (err) {
          lastError = err as Error;
          console.warn('âš ï¸ Constraint failed, trying next...', err);
        }
      }

      if (!stream) {
        throw lastError || new Error('No camera constraints worked');
      }

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.muted = true; // éŸ³å£°ã‚’ç„¡åŠ¹åŒ–

        // ãƒ“ãƒ‡ã‚ªå†ç”Ÿã®æº–å‚™å®Œäº†ã‚’å¾…ã¤
        const playPromise = videoRef.current.play();
        if (playPromise !== undefined) {
          playPromise
            .then(() => {
              console.log('âœ… Video playback started');
              console.log(`ğŸ“ Video dimensions: ${videoRef.current?.videoWidth}x${videoRef.current?.videoHeight}`);
              setDebugInfo((prev) => ({
                ...prev,
                camera: 'Playing',
                videoDimensions: `${videoRef.current?.videoWidth}x${videoRef.current?.videoHeight}`,
              }));
            })
            .catch((err) => {
              console.error('âŒ Video playback error:', err);
              setDebugInfo((prev) => ({ ...prev, camera: `Error: ${err.message}` }));
            });
        }

        // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ™‚ã®ãƒãƒ³ãƒ‰ãƒ©
        videoRef.current.onloadedmetadata = () => {
          console.log('âœ… Video metadata loaded');
          console.log(`ğŸ“ Video dimensions: ${videoRef.current?.videoWidth}x${videoRef.current?.videoHeight}`);
          setDebugInfo((prev) => ({
            ...prev,
            videoDimensions: `${videoRef.current?.videoWidth}x${videoRef.current?.videoHeight}`,
          }));
        };

        // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
        videoRef.current.onerror = (err) => {
          console.error('âŒ Video error:', err);
          setDebugInfo((prev) => ({ ...prev, camera: 'Video Error' }));
        };
      }
    } catch (err) {
      const message = err instanceof Error ? err.message : 'Failed to access camera';
      console.error('âŒ Camera access error:', err);
      setDebugInfo((prev) => ({ ...prev, camera: `Error: ${message}` }));
      setError(`ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: ${message}`);
    }
  }, []);

  // ã‚¸ã‚§ã‚¹ãƒãƒ£ã®æ¤œå‡ºã¨åˆ†é¡
  const detectGesture = useCallback(
    (currentPos: { x: number; y: number }, screenHeight: number) => {
      const now = Date.now();

      if (!prevNosePosRef.current) {
        prevNosePosRef.current = currentPos;
        gestureStartTimeRef.current = now;
        gestureStartPosRef.current = currentPos;
        return;
      }

      const deltaY = currentPos.y - prevNosePosRef.current.y;
      const totalDeltaY = currentPos.y - (gestureStartPosRef.current?.y || currentPos.y);
      const duration = now - (gestureStartTimeRef.current || now);
      const distancePercent = Math.abs(totalDeltaY) / screenHeight;

      let direction: 'none' | 'up' | 'down' = 'none';

      // ä¸‹æ–¹å‘ã‚¸ã‚§ã‚¹ãƒãƒ£ï¼ˆç¢ºå®šæ“ä½œï¼‰ï¼šä¸‹æ–¹å‘ã«ç”»é¢é«˜ã®5ï½8%ç§»å‹•
      if (deltaY > 5 && totalDeltaY > screenHeight * 0.05) {
        direction = 'down';
      }
      // ä¸Šæ–¹å‘ã‚¸ã‚§ã‚¹ãƒãƒ£ï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«æ“ä½œï¼‰ï¼šä¸Šæ–¹å‘ã«ä¸€å®šè·é›¢ç§»å‹•
      else if (deltaY < -5 && totalDeltaY < -screenHeight * 0.05) {
        direction = 'up';
      }

      setGestureState({
        direction,
        distance: distancePercent,
        duration,
      });

      prevNosePosRef.current = currentPos;
    },
    [setGestureState]
  );

  // ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆé¼»ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼‰
  const processFrame = () => {
    // ç¾åœ¨ã®çŠ¶æ…‹ã‚’å‚ç…§ã™ã‚‹ãŸã‚ã®Ref
    const currentPointerPosition = pointerPosition;
    const currentDebugInfo = debugInfo;
    if (!videoRef.current || !faceLandmarkerRef.current) {
      animationFrameRef.current = requestAnimationFrame(processFrame);
      return;
    }

    // ãƒ“ãƒ‡ã‚ªã®æº–å‚™çŠ¶æ…‹ã‚’ç¢ºèª
    const readyState = videoRef.current.readyState;
    if (readyState !== videoRef.current.HAVE_ENOUGH_DATA) {
      setDebugInfo((prev) => ({
        ...prev,
        videoReady: `${readyState}/4 (waiting for HAVE_ENOUGH_DATA)`,
      }));
      animationFrameRef.current = requestAnimationFrame(processFrame);
      return;
    }

    try {
      setDebugInfo((prev) => ({ ...prev, videoReady: 'Ready' }));

      const results = faceLandmarkerRef.current.detectForVideo(videoRef.current, Date.now());

      if (results.faceLandmarks.length > 0) {
        const landmarks = results.faceLandmarks[0];
        const noseLandmark = landmarks[NOSE_LANDMARK_INDEX];

        if (noseLandmark) {
          const screenWidth = window.innerWidth;
          const screenHeight = window.innerHeight;

          // ãƒ“ãƒ‡ã‚ªåº§æ¨™ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³åº§æ¨™ã«å¤‰æ›
          // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã«ã‚ˆã‚Šã€ã‚«ãƒ¡ãƒ©ãŒé¡è¡¨ç¤ºã«ãªã£ã¦ã„ã‚‹ã®ã«åˆã‚ã›ã¦å‹•ãã‚’å·¦å³åè»¢ã•ã›ã‚‹
          // æ„Ÿåº¦èª¿æ•´ã‚’è¿½åŠ : ä¸­å¿ƒ(0.5)ã‹ã‚‰ã®åå·®ã‚’å¢—å¹…ã™ã‚‹
          const centeredX = 1 - noseLandmark.x - 0.5;
          const centeredY = noseLandmark.y - 0.5;

          const rawScreenX = (centeredX * sensitivity + 0.5) * screenWidth;
          const rawScreenY = (centeredY * sensitivity + 0.5) * screenHeight;

          // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°å‡¦ç† (Exponential Moving Average)
          // ã‚¢ãƒ«ãƒ•ã‚¡å€¤: å°ã•ã„ã»ã©æ»‘ã‚‰ã‹ã ãŒé…å»¶ãŒå¢—ãˆã‚‹ (0.1 ~ 0.5 æ¨å¥¨)
          const alpha = 0.3;

          let smoothedX = rawScreenX;
          let smoothedY = rawScreenY;

          if (pointerPosition.isTracking) {
            smoothedX = alpha * rawScreenX + (1 - alpha) * pointerPosition.x;
            smoothedY = alpha * rawScreenY + (1 - alpha) * pointerPosition.y;
          }

          // ä¿¡é ¼åº¦ã¯æ¤œå‡ºã§ããŸæ™‚ç‚¹ã§1.0ã¨ã™ã‚‹ï¼ˆZåº§æ¨™ã¯æ·±åº¦ãªã®ã§ä¿¡é ¼åº¦ã§ã¯ãªã„ï¼‰
          const confidence = 1.0;

          setPointerPosition({
            x: smoothedX,
            y: smoothedY,
            confidence,
            isTracking: true,
          });

          // ã‚¸ã‚§ã‚¹ãƒãƒ£æ¤œå‡º
          detectGesture({ x: smoothedX, y: smoothedY }, screenHeight);
        }
      } else {
        setPointerPosition((prev) => ({ ...prev, isTracking: false }));
      }
    } catch (err) {
      console.error('âŒ Frame processing error:', err);
      setDebugInfo((prev) => ({
        ...prev,
        error: err instanceof Error ? err.message : 'Unknown error',
      }));
    }

    animationFrameRef.current = requestAnimationFrame(processFrame);
  };

  // åˆæœŸåŒ–ã¨é–‹å§‹
  useEffect(() => {
    console.log('ğŸš€ useNosePointer mounted');

    // ãƒ“ãƒ‡ã‚ªè¦ç´ ã‚’ä½œæˆï¼ˆDOMã«è¿½åŠ ã—ãªã„ã€MediaPipeã®å†…éƒ¨å‡¦ç†ç”¨ï¼‰
    if (!videoRef.current) {
      const video = document.createElement('video');
      video.autoplay = true;
      video.playsInline = true;
      video.style.display = 'none'; // éè¡¨ç¤º
      videoRef.current = video;
    }

    initializeFaceLandmarker();
    startVideoStream();

    return () => {
      console.log('ğŸ›‘ useNosePointer unmounted');
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (videoRef.current?.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  // ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã®é–‹å§‹
  useEffect(() => {
    if (!isInitialized) return;
    
    console.log('â–¶ï¸ Starting frame processing');
    
    const startProcessing = () => {
      animationFrameRef.current = requestAnimationFrame(processFrame);
    };
    
    startProcessing();

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isInitialized]);

  // ã‚¸ã‚§ã‚¹ãƒãƒ£ã®ãƒªã‚»ãƒƒãƒˆ
  const resetGesture = useCallback(() => {
    setGestureState({
      direction: 'none',
      distance: 0,
      duration: 0,
    });
    prevNosePosRef.current = null;
    gestureStartTimeRef.current = null;
    gestureStartPosRef.current = null;
  }, []);

  return {
    videoRef,
    canvasRef,
    pointerPosition,
    gestureState,
    isInitialized,
    error,
    resetGesture,
    debugInfo,
    sensitivity,
    setSensitivity,
  };
}
